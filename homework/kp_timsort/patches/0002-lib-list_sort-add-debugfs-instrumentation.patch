From 2a28d75e3066f5c5b6c2bfde5367982009d8b1a9 Mon Sep 17 00:00:00 2001
From: lane <lane@bridgewell.com>
Date: Sun, 22 Feb 2026 16:00:04 +0000
Subject: [PATCH] lib/list_sort: add debugfs instrumentation
 (CONFIG_LIST_SORT_STATS)
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

When CONFIG_LIST_SORT_STATS is enabled, list_sort() records per-call
statistics to atomic counters exposed via debugfs:

  /sys/kernel/debug/list_sort/stats   — read counters
  /sys/kernel/debug/list_sort/reset   — write to clear

Tracked metrics:
  - call_count: total list_sort() invocations
  - total_elements: sum of elements across all calls
  - total_runs: sum of natural runs detected
  - already_sorted: calls where runs == 1 (already sorted)

The stats are gated behind CONFIG_LIST_SORT_STATS (bool, default n,
depends on DEBUG_FS).  When disabled, the recording function compiles
to nothing and there is zero overhead.

This is intended for research and debugging: profiling how sorted
kernel subsystem inputs really are, to evaluate whether natural run
detection provides a meaningful benefit in practice.
---
 lib/Kconfig.debug | 16 ++++++++
 lib/list_sort.c   | 99 ++++++++++++++++++++++++++++++++++++++++++++++-
 2 files changed, 113 insertions(+), 2 deletions(-)

diff --git a/lib/Kconfig.debug b/lib/Kconfig.debug
index 4e2dfbb..2fd99a5 100644
--- a/lib/Kconfig.debug
+++ b/lib/Kconfig.debug
@@ -1838,6 +1838,22 @@ config DEBUG_LIST
 
 	  If unsure, say N.
 
+config LIST_SORT_STATS
+	bool "list_sort() runtime statistics via debugfs"
+	depends on DEBUG_FS
+	default n
+	help
+	  When enabled, list_sort() records per-call statistics (element
+	  count, run count, already-sorted count) to atomic counters
+	  exposed under /sys/kernel/debug/list_sort/.
+
+	  This is useful for profiling how sorted the inputs to
+	  list_sort() are in real workloads, but adds a small overhead
+	  per call.  When disabled, all instrumentation compiles away
+	  to nothing.
+
+	  If unsure, say N.
+
 config DEBUG_PLIST
 	bool "Debug priority linked list manipulation"
 	depends on DEBUG_KERNEL
diff --git a/lib/list_sort.c b/lib/list_sort.c
index 57b5002..1ee57fa 100644
--- a/lib/list_sort.c
+++ b/lib/list_sort.c
@@ -4,6 +4,92 @@
 #include <linux/list_sort.h>
 #include <linux/list.h>
 
+#ifdef CONFIG_LIST_SORT_STATS
+#include <linux/atomic.h>
+#include <linux/debugfs.h>
+#include <linux/seq_file.h>
+
+struct list_sort_stats {
+	atomic64_t call_count;
+	atomic64_t total_elements;
+	atomic64_t total_runs;
+	atomic64_t already_sorted;	/* cases where runs == 1 */
+};
+
+static struct list_sort_stats ls_stats;
+static struct dentry *ls_stats_dir;
+
+static int ls_stats_show(struct seq_file *m, void *v)
+{
+	s64 calls = atomic64_read(&ls_stats.call_count);
+
+	seq_printf(m, "call_count:      %lld\n", calls);
+	seq_printf(m, "total_elements:  %lld\n",
+		   atomic64_read(&ls_stats.total_elements));
+	seq_printf(m, "total_runs:      %lld\n",
+		   atomic64_read(&ls_stats.total_runs));
+	seq_printf(m, "already_sorted:  %lld\n",
+		   atomic64_read(&ls_stats.already_sorted));
+
+	if (calls > 0) {
+		seq_printf(m, "avg_elements:    %lld\n",
+			   atomic64_read(&ls_stats.total_elements) / calls);
+		seq_printf(m, "avg_runs:        %lld\n",
+			   atomic64_read(&ls_stats.total_runs) / calls);
+	}
+
+	return 0;
+}
+DEFINE_SHOW_ATTRIBUTE(ls_stats);
+
+static ssize_t ls_stats_reset_write(struct file *file, const char __user *buf,
+				    size_t count, loff_t *ppos)
+{
+	atomic64_set(&ls_stats.call_count, 0);
+	atomic64_set(&ls_stats.total_elements, 0);
+	atomic64_set(&ls_stats.total_runs, 0);
+	atomic64_set(&ls_stats.already_sorted, 0);
+	return count;
+}
+
+static const struct file_operations ls_stats_reset_fops = {
+	.write = ls_stats_reset_write,
+	.llseek = noop_llseek,
+};
+
+static int __init list_sort_stats_init(void)
+{
+	ls_stats_dir = debugfs_create_dir("list_sort", NULL);
+	if (IS_ERR(ls_stats_dir))
+		return PTR_ERR(ls_stats_dir);
+
+	debugfs_create_file("stats", 0444, ls_stats_dir, NULL,
+			    &ls_stats_fops);
+	debugfs_create_file("reset", 0200, ls_stats_dir, NULL,
+			    &ls_stats_reset_fops);
+	return 0;
+}
+
+static void __exit list_sort_stats_exit(void)
+{
+	debugfs_remove_recursive(ls_stats_dir);
+}
+
+core_initcall(list_sort_stats_init);
+module_exit(list_sort_stats_exit);
+
+static inline void list_sort_record(size_t n_elements, size_t n_runs)
+{
+	atomic64_inc(&ls_stats.call_count);
+	atomic64_add(n_elements, &ls_stats.total_elements);
+	atomic64_add(n_runs, &ls_stats.total_runs);
+	if (n_runs == 1)
+		atomic64_inc(&ls_stats.already_sorted);
+}
+#else
+static inline void list_sort_record(size_t n_elements, size_t n_runs) {}
+#endif /* CONFIG_LIST_SORT_STATS */
+
 /*
  * Returns a list organized in an intermediate format suited
  * to chaining of merge() calls: null-terminated, no reserved or
@@ -198,6 +284,7 @@ void list_sort(void *priv, struct list_head *head, list_cmp_func_t cmp)
 {
 	struct list_head *list = head->next, *pending = NULL;
 	size_t count = 0;	/* Number of runs in pending */
+	size_t n_elements = 0;
 
 	if (list == head->prev)	/* Zero or one elements */
 		return;
@@ -211,6 +298,7 @@ void list_sort(void *priv, struct list_head *head, list_cmp_func_t cmp)
 		struct list_head *run_tail;
 		struct list_head *next_list;
 		int descending;
+		size_t run_len = 1;
 
 		/* Find the least-significant clear bit in count */
 		for (bits = count; bits & 1; bits >>= 1)
@@ -240,14 +328,19 @@ void list_sort(void *priv, struct list_head *head, list_cmp_func_t cmp)
 		if (descending) {
 			/* Strictly descending run */
 			while (run_tail->next &&
-			       cmp(priv, run_tail, run_tail->next) > 0)
+			       cmp(priv, run_tail, run_tail->next) > 0) {
 				run_tail = run_tail->next;
+				run_len++;
+			}
 		} else {
 			/* Ascending run (includes single elements) */
 			while (run_tail->next &&
-			       cmp(priv, run_tail, run_tail->next) <= 0)
+			       cmp(priv, run_tail, run_tail->next) <= 0) {
 				run_tail = run_tail->next;
+				run_len++;
+			}
 		}
+		n_elements += run_len;
 
 		/* Snip the run from the remaining input */
 		next_list = run_tail->next;
@@ -278,6 +371,8 @@ void list_sort(void *priv, struct list_head *head, list_cmp_func_t cmp)
 		count++;
 	} while (list);
 
+	list_sort_record(n_elements, count);
+
 	/* End of input; merge together all the pending lists. */
 	list = pending;
 	pending = pending->prev;
-- 
2.43.0

